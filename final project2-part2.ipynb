{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eli5 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (0.14)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (0.23.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (2.10)\n",
      "Requirement already satisfied: six in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (1.11.0)\n",
      "Requirement already satisfied: attrs>16.0.0 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (18.1.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (0.8.7)\n",
      "Requirement already satisfied: scipy in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from eli5) (1.14.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->eli5) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->eli5) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from jinja2->eli5) (1.0)\n"
     ]
    }
   ],
   "source": [
    "#loading libaries\n",
    "\n",
    "!pip install eli5\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, auc, precision_score, recall_score, classification_report, roc_curve, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "random_state=147\n",
    "np.random.seed(random_state)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\spoorthi\\\\Desktop\\\\project2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:/Users/spoorthi/Desktop/project2')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (140000, 200) (60000, 200) (140000,) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Using Stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(['target', 'ID_code'], axis=1), train['target'], test_size=0.3, random_state=147, stratify=train.target)\n",
    "print('Shape:',X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(( 'LR' , LogisticRegression(solver='liblinear')))\n",
    "models.append(( 'CART' ,DecisionTreeClassifier ()))\n",
    "models.append(( 'NB' , GaussianNB()))\n",
    "models.append(('RFC', RandomForestClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_auc_score(models,scoring, num_folds=3):\n",
    "    seed = 147 \n",
    "    results = []\n",
    "    names = []\n",
    "    \n",
    "    print('-> 3-Fold cross-validation ',scoring.__name__,'score for the training data for 4 classifiers.')\n",
    "    for name, model in models:\n",
    "        kfold = KFold( n_splits=num_folds, random_state=seed)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold,verbose=3 ,scoring=make_scorer(scoring))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print(\"Algo: \", name,'::',np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores without StandardScale\n",
      "-> 3-Fold cross-validation  roc_auc_score score for the training data for 4 classifiers.\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.624, total= 1.8min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.628, total= 1.7min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.628, total= 1.9min\n",
      "Algo:  LR :: 0.6264835546403751\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.559, total= 2.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.562, total= 2.0min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.561, total=10.0min\n",
      "Algo:  CART :: 0.5605205214209749\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 14.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.668, total=   1.1s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.675, total=   0.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.679, total=   1.0s\n",
      "Algo:  NB :: 0.6741809150880748\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.500, total= 7.3min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.500, total= 7.2min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.500, total= 7.3min\n",
      "Algo:  RFC :: 0.5001406039841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 21.8min finished\n"
     ]
    }
   ],
   "source": [
    "# AUC score\n",
    "num_folds = 3\n",
    "scoring=roc_auc_score\n",
    "print(\"Scores without StandardScale\")\n",
    "cv_auc_score(models, scoring=scoring, num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores without StandardScale\n",
      "-> 3-Fold cross-validation  accuracy_score score for the training data for 4 classifiers.\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.911, total= 2.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.916, total= 2.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.913, total= 2.0min\n",
      "Algo:  LR :: 0.9136142831544322\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.831, total= 2.7min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.838, total= 3.0min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.834, total= 2.9min\n",
      "Algo:  CART :: 0.834328570085126\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  8.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.919, total=   1.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.923, total=   1.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.922, total=   1.1s\n",
      "Algo:  NB :: 0.9213500026450546\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.899, total= 9.2min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.902, total= 9.3min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 18.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.898, total=11.6min\n",
      "Algo:  RFC :: 0.8995214183060002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 30.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score\n",
    "scoring =  accuracy_score\n",
    "print(\"Scores without StandardScale\")\n",
    "cv_auc_score(models, scoring=scoring, num_folds=num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_models(models,X_train, X_test, y_train, y_test ):\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(name, ':\\n', confusion_matrix(y_test, y_pred))\n",
    "        print(name,':\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " without StandardScale\n",
      "LR :\n",
      " [[53248   723]\n",
      " [ 4434  1595]]\n",
      "LR :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     53971\n",
      "           1       0.69      0.26      0.38      6029\n",
      "\n",
      "    accuracy                           0.91     60000\n",
      "   macro avg       0.81      0.63      0.67     60000\n",
      "weighted avg       0.90      0.91      0.90     60000\n",
      "\n",
      "CART :\n",
      " [[48819  5152]\n",
      " [ 4770  1259]]\n",
      "CART :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91     53971\n",
      "           1       0.20      0.21      0.20      6029\n",
      "\n",
      "    accuracy                           0.83     60000\n",
      "   macro avg       0.55      0.56      0.56     60000\n",
      "weighted avg       0.84      0.83      0.84     60000\n",
      "\n",
      "NB :\n",
      " [[53105   866]\n",
      " [ 3860  2169]]\n",
      "NB :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     53971\n",
      "           1       0.71      0.36      0.48      6029\n",
      "\n",
      "    accuracy                           0.92     60000\n",
      "   macro avg       0.82      0.67      0.72     60000\n",
      "weighted avg       0.91      0.92      0.91     60000\n",
      "\n",
      "RFC :\n",
      " [[53971     0]\n",
      " [ 6028     1]]\n",
      "RFC :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     53971\n",
      "           1       1.00      0.00      0.00      6029\n",
      "\n",
      "    accuracy                           0.90     60000\n",
      "   macro avg       0.95      0.50      0.47     60000\n",
      "weighted avg       0.91      0.90      0.85     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" without StandardScale\")\n",
    "\n",
    "classification_report_models(models=models, X_train = X_train, X_test= X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (160000, 200)\n",
      "Shape of X_valid : (40000, 200)\n",
      "Shape of y_train : (160000,)\n",
      "Shape of y_valid : (40000,)\n"
     ]
    }
   ],
   "source": [
    "tr_X = train.drop([ 'ID_code'], axis=1)\n",
    "test_X = test.drop(['ID_code'], axis=1)\n",
    "for col in tr_X.drop(['target'], axis=1).columns:\n",
    "    tr_X[col] = ((tr_X[col] - tr_X[col].mean()) / tr_X[col].std()).astype('float32')\n",
    "for col in test_X.columns:\n",
    "    test_X[col] = ((test_X[col] - test_X[col].mean()) / test_X[col].std()).astype('float32')\n",
    "  \n",
    "\n",
    "#Training data\n",
    "X=tr_X.drop(['target'],axis=1)\n",
    "Y=train['target']\n",
    "#StratifiedKFold cross validator\n",
    "cv=StratifiedKFold(n_splits=5,random_state=147,shuffle=True)\n",
    "for train_index,valid_index in cv.split(X,Y):\n",
    "    X_train1, X_valid=X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train1, y_valid=Y.iloc[train_index], Y.iloc[valid_index]\n",
    "\n",
    "print('Shape of X_train :',X_train1.shape)\n",
    "print('Shape of X_valid :',X_valid.shape)\n",
    "print('Shape of y_train :',y_train1.shape)\n",
    "print('Shape of y_valid :',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthetic Minority Oversampling Technique\n",
    "sm = SMOTE(random_state=147)\n",
    "#Generating synthetic data points\n",
    "X_smote,y_smote=sm.fit_sample(X_train1,y_train1)\n",
    "X_smote_v,y_smote_v=sm.fit_sample(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_models(models,X_train = X_smote, X_test= X_smote_v, y_train=y_smote, y_test=y_smote_v):\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(name, ':\\n', confusion_matrix(y_test, y_pred))\n",
    "        print(name,':\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR :\n",
      " [[28535  7445]\n",
      " [ 7688 28292]]\n",
      "LR :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79     35980\n",
      "           1       0.79      0.79      0.79     35980\n",
      "\n",
      "    accuracy                           0.79     71960\n",
      "   macro avg       0.79      0.79      0.79     71960\n",
      "weighted avg       0.79      0.79      0.79     71960\n",
      "\n",
      "CART :\n",
      " [[26718  9262]\n",
      " [18362 17618]]\n",
      "CART :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66     35980\n",
      "           1       0.66      0.49      0.56     35980\n",
      "\n",
      "    accuracy                           0.62     71960\n",
      "   macro avg       0.62      0.62      0.61     71960\n",
      "weighted avg       0.62      0.62      0.61     71960\n",
      "\n",
      "NB :\n",
      " [[34250  1730]\n",
      " [ 7578 28402]]\n",
      "NB :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88     35980\n",
      "           1       0.94      0.79      0.86     35980\n",
      "\n",
      "    accuracy                           0.87     71960\n",
      "   macro avg       0.88      0.87      0.87     71960\n",
      "weighted avg       0.88      0.87      0.87     71960\n",
      "\n",
      "RFC :\n",
      " [[35767   213]\n",
      " [18433 17547]]\n",
      "RFC :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79     35980\n",
      "           1       0.99      0.49      0.65     35980\n",
      "\n",
      "    accuracy                           0.74     71960\n",
      "   macro avg       0.82      0.74      0.72     71960\n",
      "weighted avg       0.82      0.74      0.72     71960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classification_report_models(models=models, X_train = X_smote, X_test= X_smote_v, y_train=y_smote, y_test=y_smote_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from lightgbm) (1.14.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\spoorthi\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    " !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with simple train_test_split stratified data\n",
    "#training data\n",
    "\n",
    "lgb_train=lgb.Dataset(X_train,label=y_train)\n",
    "#validation data\n",
    "lgb_valid=lgb.Dataset(X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'boosting_type': 'gbdt', \n",
    "          'max_depth' : -1, #no limit for max_depth if <0\n",
    "          'objective': 'binary',\n",
    "          'boost_from_average':False, \n",
    "          'nthread': 20,\n",
    "          'metric':'auc',\n",
    "          'num_leaves': 50,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_bin': 100,      #default 255\n",
    "          'subsample_for_bin': 100,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'bagging_fraction':0.5,\n",
    "          'bagging_freq':5,\n",
    "          'feature_fraction':0.08,\n",
    "          'min_split_gain': 0.45, #>0\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'is_unbalance':True,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's auc: 0.90473\ttraining's f1: 0.501978\tvalid_1's auc: 0.861808\tvalid_1's f1: 0.453369\n",
      "[200]\ttraining's auc: 0.916043\ttraining's f1: 0.520313\tvalid_1's auc: 0.871636\tvalid_1's f1: 0.463072\n",
      "[300]\ttraining's auc: 0.921524\ttraining's f1: 0.530338\tvalid_1's auc: 0.874694\tvalid_1's f1: 0.471082\n",
      "[400]\ttraining's auc: 0.925516\ttraining's f1: 0.538659\tvalid_1's auc: 0.877351\tvalid_1's f1: 0.475187\n",
      "[500]\ttraining's auc: 0.929301\ttraining's f1: 0.544808\tvalid_1's auc: 0.879744\tvalid_1's f1: 0.476082\n",
      "[600]\ttraining's auc: 0.933148\ttraining's f1: 0.550923\tvalid_1's auc: 0.881459\tvalid_1's f1: 0.481687\n",
      "[700]\ttraining's auc: 0.935784\ttraining's f1: 0.555645\tvalid_1's auc: 0.882739\tvalid_1's f1: 0.484115\n",
      "[800]\ttraining's auc: 0.938713\ttraining's f1: 0.562333\tvalid_1's auc: 0.884134\tvalid_1's f1: 0.486005\n",
      "[900]\ttraining's auc: 0.941561\ttraining's f1: 0.570638\tvalid_1's auc: 0.885102\tvalid_1's f1: 0.489819\n",
      "[1000]\ttraining's auc: 0.944108\ttraining's f1: 0.574578\tvalid_1's auc: 0.885893\tvalid_1's f1: 0.491166\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.944108\ttraining's f1: 0.574578\tvalid_1's auc: 0.885893\tvalid_1's f1: 0.491166\n"
     ]
    }
   ],
   "source": [
    "num_rounds=1000\n",
    "lgbm1= lgb.train(params,lgb_train,num_rounds,valid_sets=[lgb_train,lgb_valid],feval=lgb_f1_score,verbose_eval=100,early_stopping_rounds = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: Simple Lightgbm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46422,  7549],\n",
       "       [ 1609,  4420]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix: Simple Lightgbm')\n",
    "confusion_matrix(y_test, lgbm1.predict(X_test).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with StratifiedKFold()+SMOTE() data\n",
    "#training data\n",
    "lgb_train2=lgb.Dataset(X_smote,label=y_smote)\n",
    "#validation data\n",
    "lgb_valid2=lgb.Dataset(X_smote_v,label=y_smote_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5000 rounds\n",
      "[1000]\ttraining's auc: 0.956207\ttraining's f1: 0.885727\tvalid_1's auc: 0.93558\tvalid_1's f1: 0.854468\n",
      "[2000]\ttraining's auc: 0.969384\ttraining's f1: 0.906972\tvalid_1's auc: 0.944535\tvalid_1's f1: 0.867009\n",
      "[3000]\ttraining's auc: 0.977196\ttraining's f1: 0.920779\tvalid_1's auc: 0.948302\tvalid_1's f1: 0.871963\n",
      "[4000]\ttraining's auc: 0.982755\ttraining's f1: 0.931635\tvalid_1's auc: 0.950366\tvalid_1's f1: 0.874556\n",
      "[5000]\ttraining's auc: 0.987019\ttraining's f1: 0.940849\tvalid_1's auc: 0.951436\tvalid_1's f1: 0.875119\n",
      "[6000]\ttraining's auc: 0.990332\ttraining's f1: 0.949184\tvalid_1's auc: 0.952014\tvalid_1's f1: 0.875143\n",
      "[7000]\ttraining's auc: 0.992891\ttraining's f1: 0.957019\tvalid_1's auc: 0.952321\tvalid_1's f1: 0.875251\n",
      "[8000]\ttraining's auc: 0.99484\ttraining's f1: 0.963922\tvalid_1's auc: 0.952444\tvalid_1's f1: 0.875006\n",
      "[9000]\ttraining's auc: 0.996309\ttraining's f1: 0.97027\tvalid_1's auc: 0.95262\tvalid_1's f1: 0.874528\n",
      "[10000]\ttraining's auc: 0.997386\ttraining's f1: 0.975572\tvalid_1's auc: 0.952645\tvalid_1's f1: 0.873892\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's auc: 0.997386\ttraining's f1: 0.975572\tvalid_1's auc: 0.952645\tvalid_1's f1: 0.873892\n"
     ]
    }
   ],
   "source": [
    "num_rounds=10000\n",
    "lgbm3= lgb.train(params,lgb_train2,num_rounds,valid_sets=[lgb_train2,lgb_valid2],feval=lgb_f1_score,verbose_eval=1000,early_stopping_rounds = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: SMOTE Lightgbm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53971,     0],\n",
       "       [ 6029,     0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print('Confusion matrix: SMOTE Lightgbm')\n",
    "confusion_matrix(y_test, lgbm3.predict(X_test).round())\n",
    "#plot_roc(y_test,  lgbm3.predict(X_test).round(), name='SMOTE LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#final submission\n",
    "\n",
    "X_test=test.drop(['ID_code'],axis=1)\n",
    "#predict the model, probability predictions\n",
    "lightgbm_predict_prob3=lgbm3.predict(X_test,random_state=42,num_iteration=lgbm3.best_iteration)\n",
    "lightgbm_predict_prob1=lgbm1.predict(X_test,random_state=42,num_iteration=lgbm1.best_iteration)\n",
    "\n",
    "#Convert to binary output 1 or 0\n",
    "lightgbm_predict3=lightgbm_predict_prob3.round()\n",
    "lightgbm_predict1=lightgbm_predict_prob1.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target\n",
       "0  test_0       0\n",
       "1  test_1       0\n",
       "2  test_2       0\n",
       "3  test_3       0\n",
       "4  test_4       0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit=pd.DataFrame({'ID_code':test['ID_code'].values})\n",
    "submit1=pd.DataFrame({'ID_code':test['ID_code'].values})\n",
    "\n",
    "#submit['lightgbm_predict_prob']=lightgbm_predict_prob3\n",
    "submit['target']=lightgbm_predict3.astype(int)\n",
    "submit1['target']=lightgbm_predict1.astype(int)\n",
    "\n",
    "submit.to_csv('submission.csv',index=False)\n",
    "submit1.to_csv('submission1.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target\n",
       "0  test_0       0\n",
       "1  test_1       1\n",
       "2  test_2       1\n",
       "3  test_3       1\n",
       "4  test_4       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target\n",
       "0  test_0       0\n",
       "1  test_1       0\n",
       "2  test_2       0\n",
       "3  test_3       0\n",
       "4  test_4       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
